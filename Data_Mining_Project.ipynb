{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPHfyRbNzKcv"
   },
   "source": [
    "# Data Analysis Jupyter Notebook\n",
    "\n",
    "This Jupyter Notebook is a template for data analysis. It includes installation of necessary libraries, loading datasets, and displaying basic information and statistics for each dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwQ_z05hzsLh"
   },
   "source": [
    "## Environment preparation\n",
    "\n",
    "First of all, we will install all the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfOUKxJsznAp",
    "outputId": "efba5e14-dcaf-4881-fa82-c4351994e134"
   },
   "outputs": [],
   "source": [
    "#capture\n",
    "#!python -m pip install --upgrade pip\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#!pip install scipy\n",
    "#!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "it-bBY0rz4c9"
   },
   "source": [
    "## Data Understanding\n",
    "\n",
    "We will read the datasets in order to understand the information that they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8h4TwXZMx9KN",
    "outputId": "b53599ac-a442-40c2-890a-c2af5e0e18d3"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the three datasets\n",
    "incidents_dataset = pd.read_csv('./project_datasets/incidents.csv', low_memory=False)\n",
    "pbsy_dataset = pd.read_csv('./project_datasets/povertyByStateYear.csv')\n",
    "ysdh_dataset = pd.read_csv('./project_datasets/year_state_district_house.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the datasets, we will execute some commands to have a preview about the information.\n",
    "\n",
    "With `info()`, we will see the names of the columns of the datasets, the data type and the amount of non null values that they have. With `head()`, the first 5 rows of each dataset, that they will help us to have the idea of the dataset row types. Eventually, with `describe()` we will obtain the statisctical values of the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0VFQypQ2fRn",
    "outputId": "d2bf1ede-9e41-4f94-9abb-c5500255a1ce"
   },
   "outputs": [],
   "source": [
    "# Display basic information about each dataset\n",
    "print(\"\\n------- Incidents Info:-------\")\n",
    "print(incidents_dataset.info())\n",
    "\n",
    "print(\"\\n------- Dataset 2 Info:-------\")\n",
    "print(pbsy_dataset.info())\n",
    "\n",
    "print(\"\\n------- Dataset 3 Info:-------\")\n",
    "print(ysdh_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5519wFl2di4",
    "outputId": "32dde122-4939-4201-dda2-7838f0e97d93"
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of each dataset\n",
    "print(\"------- Incidents -------\")\n",
    "print(incidents_dataset.head())\n",
    "\n",
    "print(\"\\n------- Poverty By State and Year -------\")\n",
    "print(pbsy_dataset.head())\n",
    "\n",
    "print(\"\\n------- Year State District House -------\")\n",
    "print(ysdh_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the data types of some of the columns are not correct, so we will fix them. For example, `date` columns has data type `object`, so we will convert it on datetime and some columns that contain numeric values are as `object` type as well, so we will change them. Also here, the modifications are done in the incidents dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime\n",
    "incidents_dataset['date'] = pd.to_datetime(incidents_dataset['date'])\n",
    "\n",
    "# Convert numeric data from object to numeric, handling errors\n",
    "incidents_dataset['state_senate_district'] = pd.to_numeric(incidents_dataset['state_senate_district'], errors='coerce')\n",
    "incidents_dataset['min_age_participants'] = pd.to_numeric(incidents_dataset['min_age_participants'], errors='coerce')\n",
    "incidents_dataset['max_age_participants'] = pd.to_numeric(incidents_dataset['max_age_participants'], errors='coerce')\n",
    "incidents_dataset['avg_age_participants'] = pd.to_numeric(incidents_dataset['avg_age_participants'], errors='coerce')\n",
    "incidents_dataset['n_participants_child'] = pd.to_numeric(incidents_dataset['n_participants_child'], errors='coerce').astype('Int64')\n",
    "incidents_dataset['n_participants_teen'] = pd.to_numeric(incidents_dataset['n_participants_teen'], errors='coerce').astype('Int64')\n",
    "incidents_dataset['n_participants_adult'] = pd.to_numeric(incidents_dataset['n_participants_adult'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Verify the data types after conversion\n",
    "print(\"\\nData Types After Conversion:\\n ---- Dataset 1 ----\\n\", incidents_dataset.dtypes)\n",
    "print(\"\\n ---- Dataset 2 ----\\n\", pbsy_dataset.dtypes)\n",
    "print(\"\\n ---- Dataset 3 ----\\n\", ysdh_dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1HrThg42fZE",
    "outputId": "a2868822-604c-410b-a563-9b6a6331906d"
   },
   "outputs": [],
   "source": [
    "# Display basic statistics for each dataset\n",
    "print(\"\\n------- Incidents Statistics:-------\")\n",
    "print(incidents_dataset.describe())\n",
    "\n",
    "print(\"\\n------- Poverty By State and Year Statistics:-------\")\n",
    "print(pbsy_dataset.describe())\n",
    "\n",
    "print(\"\\n------- Dataset 3 Statistics:-------\")\n",
    "print(ysdh_dataset.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets columns description\n",
    "\n",
    "After analyzing the datasets with the previous commands, we will briefly describe each of the columns of the three datasets:\n",
    "\n",
    "#### Incidents Dataset (incidents.csv)\n",
    "\n",
    "- **Date of Incident (`date`):** This variable represents the date when the gun incident occurred.\n",
    "- **State (`state`):** Indicates the state where the incident took place.\n",
    "- **City or County (`city_or_county`):** Specifies the city or county where the incident occurred.\n",
    "- **Address (`address`):** Represents the specific address where the incident took place.\n",
    "- **Geographical Coordinates (`latitude, longitude`):** Provides the latitude and longitude of the incident location.\n",
    "- **Congressional District (`congressional_district`):** Specifies the congressional district where the incident occurred.\n",
    "- **State House District (`state_house_district`):** Represents the state house district of the incident.\n",
    "- **State Senate District (`state_senate_district`):** Indicates the state senate district where the incident took place.\n",
    "- **Participant Age (`participant_age1`):** Represents the exact age of one randomly chosen participant in the incident.\n",
    "- **Participant Age Group (`participant_age_group1`):** Specifies the age group of one randomly chosen participant.\n",
    "- **Participant Gender (`participant_gender1`):** Indicates the gender of one randomly chosen participant.\n",
    "- **Minimum, Average, and Maximum Age of Participants (`min_age_participants, avg_age_participants, max_age_participants`):** Provide statistical measures of participant ages.\n",
    "- **Number of Participants by Age Group (`n_participants_child, n_participants_teen, n_participants_adult`):** Gives the count of participants in different age groups.\n",
    "- **Number of Males and Females (`n_males, n_females`):** Specifies the count of male and female participants.\n",
    "- **Number of People Killed and Injured (`n_killed, n_injured`):** Represents the count of people killed and injured in the incident.\n",
    "- **Number of Arrested and Unharmed Participants (`n_arrested, n_unharmed`):** Indicates the count of participants arrested and unharmed.\n",
    "- **Total Number of Participants (`n_participants`):** Represents the total number of participants in the incident.\n",
    "- **Additional Notes (`notes`):** Provides additional information or notes about the incident.\n",
    "- **Incident Characteristics (`incident_characteristics1, incident_characteristics2`):** Specifies the characteristics of the incident.\n",
    "\n",
    "#### Poverty By State and Year Dataset (povertyByStateYear.csv)\n",
    "\n",
    "- **State (`state`):** The name of the state.\n",
    "- **Year (`year`):** The year for which the poverty rate is recorded.\n",
    "- **Poverty percentage (`povertyPercentage`):** The percentage of the population in poverty for a specific state and year.\n",
    "\n",
    "#### Year State District House Dataset (year_state_district_house.csv)\n",
    "\n",
    "- **Year (`year`):** The year of the election.\n",
    "- **State (`state`):** The name of the state for which election results are recorded.\n",
    "- **State (`congressional_district`):** The congressional district number for which election results are recorded.\n",
    "- **Party (`party`):** The political party associated with the candidate.\n",
    "- **Candidate votes (`candidatevotes`):** The number of votes received by a specific candidate in a particular congressional district.\n",
    "- **Total votes (`totalvotes`):** The total number of votes cast in a particular congressional district."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMe9jOrW5aWI"
   },
   "source": [
    "### Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the idea of the content of the dataset, we will perform an analysis of the quality of the data.\n",
    "\n",
    "Firstly, we will check for missing values in the dataset 1 columns. We will perform this analysis in the dataset of incidents only, because the other two do not have missing values.\n",
    "\n",
    "With the next graph we can see the distribution of missing values for each column. For example, we can see that the column with more missing values is  `incident_characteristic2`. This occurs because most of the incidents do not have two characteristics, but just one, since we can see that `incident_characteristic1` has almost no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "Jh8ZPjQp5HsW",
    "outputId": "ca13b341-6656-4303-ca0f-d4da93167d6c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = incidents_dataset.isnull().sum()\n",
    "#print(\"\\nMissing Values:\\n\", missing_values)\n",
    "\n",
    "# Plotting the sum of missing values for each column using a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=missing_values.index, y=missing_values.values, hue=missing_values.index, palette='flare', legend=False)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Sum of Missing Values in Incidents Dataset')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases that do not have the characteristic specified (`incident_characteristics1` = *null*), would be removed, since we would not know what was the incident about, and it does not make sense to analyze them.\n",
    "\n",
    "The data that doesn't have any `address` and any `latitude` and `longitude` will be eliminated since it does not make sense that an incident has not occurred anywhere and also the number of incidents with this condition is insignificant compared to the number of total incidents. The cases that have an address but no coordinates, or vice versa, would be maintained.\n",
    "\n",
    "With the column of `participant_age1` we will fill the nulls with the average age of the participants, if this is not null.\n",
    "\n",
    "Although many other columns have empty values, are columns that null values are possible, since they do not necessarily have to have values. Therefore, we will leave them as there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate the data that have null in adress and latitude, and in adress and longitude\n",
    "incidents_dataset = incidents_dataset.dropna(subset=['address', 'latitude'], how='all', inplace=False)\n",
    "incidents_dataset = incidents_dataset.dropna(subset=['address', 'longitude'], how='all', inplace=False)\n",
    "# Rename the other nulls with no_data\n",
    "valor_reemplazo = 'no_data'\n",
    "actualGender = 'Male'\n",
    "totalChilds = 0\n",
    "totalTeens = 0\n",
    "totalAdults = 0\n",
    "totalMales = 0\n",
    "totalFemales = 0\n",
    "totalArrested = 0\n",
    "totalUnharmed = 0 \n",
    "def setAgeGroup(a):\n",
    "    if a < 12:\n",
    "        return 'Child 0-11'\n",
    "    elif a < 18:\n",
    "        return 'Teen 12-17'\n",
    "    return 'Adult 18+'\n",
    "def sumTotalNumber(a, t):\n",
    "    if a is not None:\n",
    "        return t\n",
    "    else:\n",
    "        return t + a\n",
    "\n",
    "actualGender = 'Male'  # Asegúrate de inicializar actualGender antes del bucle si aún no está definido\n",
    "totalChilds, totalTeens, totalAdults, totalMales, totalFemales, totalArrested, totalUnharmed = 0, 0, 0, 0, 0, 0, 0  # Inicializar las variables acumulativas\n",
    "\n",
    "for index, x in incidents_dataset.iterrows():\n",
    "    # Primero limpiamos las edades mínima, promedio y máxima de los participantes\n",
    "    if pd.isnull(x['min_age_participants']):\n",
    "        if not pd.isnull(x['avg_age_participants']):\n",
    "            if not pd.isnull(x['max_age_participants']):\n",
    "                k = x['avg_age_participants'] - (x['max_age_participants'] - x['avg_age_participants'])\n",
    "                if k < 0:\n",
    "                    incidents_dataset.at[index, 'min_age_participants'] = 0\n",
    "                else:\n",
    "                    incidents_dataset.at[index, 'min_age_participants'] = k\n",
    "            else:\n",
    "                incidents_dataset.at[index, 'min_age_participants'] = x['avg_age_participants']\n",
    "\n",
    "    if pd.isnull(x['max_age_participants']):\n",
    "        if not pd.isnull(x['avg_age_participants']):\n",
    "            if not pd.isnull(x['min_age_participants']):\n",
    "                incidents_dataset.at[index, 'max_age_participants'] = x['avg_age_participants'] + (x['avg_age_participants'] - x['min_age_participants'])\n",
    "            else:\n",
    "                incidents_dataset.at[index, 'max_age_participants'] = x['avg_age_participants']\n",
    "\n",
    "    if pd.isnull(x['avg_age_participants']):\n",
    "        if not (pd.isnull(x['min_age_participants']) or pd.isnull(x['max_age_participants'])):\n",
    "            incidents_dataset.at[index, 'avg_age_participants'] = (float(x['min_age_participants']) + float(x['max_age_participants'])) / 2\n",
    "        elif pd.isnull(x['min_age_participants']):\n",
    "            incidents_dataset.at[index, 'avg_age_participants'] = float(x['max_age_participants'])\n",
    "        else:\n",
    "            incidents_dataset.at[index, 'avg_age_participants'] = float(x['min_age_participants'])\n",
    "\n",
    "    # Para la edad aleatoria del participante, usaremos el promedio; si es nula, usamos la mínima o la máxima\n",
    "    if pd.isnull(x['participant_age1']):\n",
    "        if (not pd.isnull(x['avg_age_participants'])) and (x['avg_age_participants'] > 0):\n",
    "            incidents_dataset.at[index, 'participant_age1'] = float(x['avg_age_participants'])\n",
    "        elif (not pd.isnull(x['min_age_participants'])) and (x['min_age_participants'] > 0):\n",
    "            incidents_dataset.at[index, 'participant_age1'] = float(x['min_age_participants'])\n",
    "        elif (not pd.isnull(x['max_age_participants'])) and (x['max_age_participants'] > 0): \n",
    "            incidents_dataset.at[index, 'participant_age1'] = float(x['max_age_participants'])\n",
    "\n",
    "    # Para el grupo de edad aleatorio, hacemos lo mismo que para participant_age1\n",
    "    if pd.isnull(x['participant_age_group1']):\n",
    "        if not pd.isnull(x['avg_age_participants']):\n",
    "            incidents_dataset.at[index, 'participant_age_group1'] = setAgeGroup(float(x['avg_age_participants']))\n",
    "        elif not pd.isnull(x['min_age_participants']):\n",
    "            incidents_dataset.at[index, 'participant_age_group1'] = setAgeGroup(float(x['min_age_participants']))\n",
    "        elif not pd.isnull(x['max_age_participants']):\n",
    "            incidents_dataset.at[index, 'participant_age_group1'] = setAgeGroup(float(x['max_age_participants']))\n",
    "        elif not pd.isnull(x['participant_age1']):\n",
    "            incidents_dataset.at[index, 'participant_age_group1'] = setAgeGroup(float(x['participant_age1']))\n",
    "\n",
    "    # Para la edad aleatoria del participante de cada fila, la llenamos con un género diferente al anterior\n",
    "    if pd.isnull(x['participant_gender1']):\n",
    "        incidents_dataset.at[index, 'participant_gender1'] = actualGender\n",
    "        actualGender = 'Female' if actualGender == 'Male' else 'Male'\n",
    "\n",
    "    # Acumular totales\n",
    "    totalChilds = sumTotalNumber(x['n_participants_child'], totalChilds)\n",
    "    totalTeens = sumTotalNumber(x['n_participants_teen'], totalTeens)\n",
    "    totalAdults = sumTotalNumber(x['n_participants_adult'], totalAdults)\n",
    "    totalMales = sumTotalNumber(x['n_males'], totalMales)\n",
    "    totalFemales = sumTotalNumber(x['n_females'], totalFemales)\n",
    "    totalArrested = sumTotalNumber(x['n_arrested'], totalArrested)\n",
    "    totalUnharmed = sumTotalNumber(x['n_unharmed'], totalUnharmed)\n",
    "\n",
    "\n",
    "#For the rest numeral attributes we just do the average of all the cases\n",
    "incidents_dataset['n_participants_child'].fillna(round(totalChilds/len(incidents_dataset)), inplace=True)\n",
    "incidents_dataset['n_participants_teen'].fillna(round(totalTeens/len(incidents_dataset)), inplace=True)\n",
    "incidents_dataset['n_participants_adult'].fillna(round(totalAdults/len(incidents_dataset)), inplace=True)\n",
    "incidents_dataset['n_males'].fillna(round(totalMales/len(incidents_dataset)), inplace=True)\n",
    "incidents_dataset['n_females'].fillna(round(totalFemales/len(incidents_dataset)), inplace=True)\n",
    "incidents_dataset['n_arrested'].fillna(round(totalArrested/len(incidents_dataset)), inplace=True)\n",
    "incidents_dataset['n_unharmed'].fillna(round(totalUnharmed/len(incidents_dataset)), inplace=True)\n",
    "\n",
    "# Print mising values label\n",
    "missing_values = incidents_dataset.isnull().sum()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=missing_values.index, y=missing_values.values, hue=missing_values.index, palette='flare', legend=False)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Sum of Missing Values in Incidents Dataset')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we will check for duplicated values in the datasets. We can see that the incidents dataset is the only one that has duplicates, so we remove them and then verify that we have done it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rA-N7o_O5l2Z",
    "outputId": "29b40d78-96b9-449b-dde1-ff13f93ef20a"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "d1_duplicates = incidents_dataset.duplicated().sum()\n",
    "print(\"- Number of Duplicates:\", d1_duplicates)\n",
    "\n",
    "# Remove duplicate rows\n",
    "incidents_dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verify the removal of duplicates\n",
    "d1_duplicates_after_removal = incidents_dataset.duplicated().sum()\n",
    "print(\"\\n- Number of Duplicates After Removal:\", d1_duplicates_after_removal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1BrLIG4IlsT",
    "outputId": "a1c8227d-bcef-4f1d-d1ea-1157235574ad"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "d2_duplicates = pbsy_dataset.duplicated().sum()\n",
    "print(\"- Number of Duplicates:\", d2_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5sVyh1FIlv8",
    "outputId": "b83a2e16-21c9-4fed-adc9-7379d5b2e2f9"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "d3_duplicates = ysdh_dataset.duplicated().sum()\n",
    "print(\"- Number of Duplicates:\", d3_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmhv3ksq7Y-r"
   },
   "source": [
    "### Distribution of variables\n",
    "\n",
    "Then, we will see the distribution of the variables in the different datasest.\n",
    "\n",
    "#### Poverty Percentages evaluation\n",
    "\n",
    "To start, we will see the distribution of the poverty rates by states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=pbsy_dataset, x='state', y='povertyPercentage', hue='state', palette='viridis', dodge=False)\n",
    "plt.title('Poverty Percentage by State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Poverty Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the United State state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=pbsy_dataset, x='year', y='povertyPercentage', hue='year', palette='viridis', dodge=False)\n",
    "plt.title('Boxplot of Poverty Percentage Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Poverty Percentage')\n",
    "plt.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we will see the general distribution of the poverty rates throughout all the US. We can see that even tough there are some rates that are higher, the distribution is skewed right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=pbsy_dataset, x='povertyPercentage', bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Poverty Percentage')\n",
    "plt.xlabel('Poverty Percentage')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of the voting\n",
    "\n",
    "Similar situation occurs with the boxplots of the votes, where we can see a normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "-5fgfanTJDuv",
    "outputId": "95f0aee2-64e3-4c9e-d327-2786ae4188d3"
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of candidatevotes for outlier detection\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=ysdh_dataset, x='candidatevotes', color='skyblue')\n",
    "plt.title('Boxplot of Candidate Votes')\n",
    "plt.show()\n",
    "\n",
    "# Handle outliers (if any)\n",
    "#ysdh_dataset['candidatevotes'] = winsorize(ysdh_dataset['candidatevotes'], limits=[0.05, 0.05])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSi50038DAmp"
   },
   "source": [
    "#### Evolution of Incidents Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evolution of the incidents over time is one of the most relevant topics to analyze, so in the next graph we display it. We can see something strange. There are values that start around 2014, that finish around middle of 2018, and then values that restart in 2028. We don't know why that data is in the dataset, if by mistake or if it is some kind of prediction that they have made, where they have the incident data that they would like to have for the future. Whatever it is, for our analysis the future data is not relevant, so we are going to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "lWTjxMlL5l7v",
    "outputId": "3e18774f-a560-498f-bed8-48acc886b649"
   },
   "outputs": [],
   "source": [
    "# Count the number of incidents for each date\n",
    "incident_counts = incidents_dataset['date'].value_counts().sort_index()\n",
    "\n",
    "# Plotting the evolution of the amount of incidents over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=incident_counts.index, y=incident_counts.values, marker='o', color='skyblue')\n",
    "plt.title('Evolution of Incidents Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with 'date' in the future\n",
    "incidents_dataset = incidents_dataset[incidents_dataset['date'].dt.year < 2028]\n",
    "\n",
    "# Verify the changes\n",
    "print(incidents_dataset['date'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of incidents for each date\n",
    "incident_counts = incidents_dataset['date'].value_counts().sort_index()\n",
    "\n",
    "# Plotting the evolution of the amount of incidents over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=incident_counts.index, y=incident_counts.values, marker='o', color='skyblue')\n",
    "plt.title('Evolution of Incidents Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next issue that we can see is the difference between the incidents until 2014, with the incidents between 2014 and 2018. This does not occur because 2013 was the safest year of the history, but because there are way less values in the dataset than in the rest of the years. Therefore, in order not to alter the results, we have decided to remove entries older than 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the 'date' column and create a new 'year' column\n",
    "incidents_dataset['year'] = incidents_dataset['date'].dt.year\n",
    "\n",
    "# Count the number of incidents by year\n",
    "incident_counts_by_year = incidents_dataset['year'].value_counts().sort_index()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Number of Incidents by Year:\")\n",
    "print(incident_counts_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with 'date' in the future\n",
    "incidents_dataset = incidents_dataset[incidents_dataset['date'].dt.year > 2013]\n",
    "\n",
    "# Verify the changes\n",
    "print(incidents_dataset['date'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final result of the plot would be the next one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of incidents for each date\n",
    "incident_counts = incidents_dataset['date'].value_counts().sort_index()\n",
    "\n",
    "# Plotting the evolution of the amount of incidents over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=incident_counts.index, y=incident_counts.values, marker='o', color='skyblue')\n",
    "plt.title('Evolution of Incidents Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gO0nqrWDDdQ"
   },
   "source": [
    "#### Geographical Distribution of Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "do5wMuMk95US",
    "outputId": "edd8beb6-58e4-4811-b11d-39b646ab0e36"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "world_filepath = './110m_cultural/ne_110m_admin_0_countries.shp'\n",
    "world = gpd.read_file(world_filepath)\n",
    "\n",
    "# Create a GeoDataFrame from the incidents_dataset DataFrame\n",
    "gdf = gpd.GeoDataFrame(incidents_dataset, geometry=gpd.points_from_xy(incidents_dataset.longitude, incidents_dataset.latitude))\n",
    "\n",
    "# Plot the world map\n",
    "world.plot(figsize=(12, 8), color='lightgrey', edgecolor='black')\n",
    "\n",
    "# Plot the scatter plot on top of the world map\n",
    "scatter_plot = sns.scatterplot(x='longitude', y='latitude', data=incidents_dataset, hue='n_killed', palette='viridis',\n",
    "                               size='n_injured', sizes=(20, 200), alpha=0.7)\n",
    "\n",
    "# Move the legend outside the chart\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.title('Geographical Distribution of Incidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Geographical data fixing\n",
    "\n",
    "As we see in the data understanding section, there were some outliers in the geographical data, since it was visible that there were some incidents around India, when there would be just incidents from the USA.\n",
    "\n",
    "To fix that we refined the filtering criteria based on the latitude and longitude values. We set the latitude and longitude ranges to cover the area of the United States, including Alaska and Hawaii that have different coordinates that the main US region. These adjusted ranges ensure that incidents falling within the geographical coordinates of the entire United States are retained in the filtered dataset. This refined filtering approach allows for the accurate representation of incident locations on the geographical scatter plot while eliminating data points located outside the intended area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming the latitude and longitude ranges for the United States\n",
    "us_latitude_range = (18, 71)\n",
    "us_longitude_range = (-179, -66)\n",
    "\n",
    "# Filter out incidents outside the US coordinates\n",
    "incidents_dataset_us = incidents_dataset[(incidents_dataset['latitude'].between(*us_latitude_range)) &\n",
    "                        (incidents_dataset['longitude'].between(*us_longitude_range))]\n",
    "\n",
    "# Create a GeoDataFrame from the filtered dataset\n",
    "gdf_us = gpd.GeoDataFrame(incidents_dataset_us, geometry=gpd.points_from_xy(incidents_dataset_us.longitude, incidents_dataset_us.latitude))\n",
    "\n",
    "# Plot the world map\n",
    "world_filepath = './110m_cultural/ne_110m_admin_0_countries.shp'\n",
    "world.plot(figsize=(12, 8), color='lightgrey', edgecolor='black')\n",
    "\n",
    "# Plot the scatter plot on top of the world map for the US incidents\n",
    "scatter_plot = sns.scatterplot(x='longitude', y='latitude', data=incidents_dataset_us, hue='n_killed', palette='viridis',\n",
    "                               size='n_injured', sizes=(20, 200), alpha=0.7)\n",
    "\n",
    "# Move the legend outside the chart\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.title('Geographical Distribution of Incidents in the US')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEPm1u6oDHHZ"
   },
   "source": [
    "#### Distribution of Participant Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the characteristics of the participants in the incidents it is one of the keys of our analysis, so we will start with the age of the participants. In the next graph we can have a preview of the distribution of the ages. We can see that there are ages that are greater than 100 years, including an entry with 311 years which is the maximum. This is almost impossible, so we will remove the values that have participants older than 110 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "RnwE42iZ7h82",
    "outputId": "abaadc08-db79-4392-bf57-4d512a789d36"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=incidents_dataset, x='participant_age1', bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Participant Ages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove participants older than 110 years\n",
    "incidents_dataset = incidents_dataset[incidents_dataset['participant_age1'] <= 110]\n",
    "\n",
    "# Verify the changes\n",
    "print(incidents_dataset['participant_age1'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=incidents_dataset, x='participant_age1', bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Participant Ages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Participant Gender\n",
    "\n",
    "Then we will analyze the gender of the participants. There are male and female values, but we also have an entry with the gender 'Male, female'. Since it is just one entry, and to simplify the analysis, we will remove this entry, converting in to \"Male\" and just have female and male categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOYoXyz_C7Kx"
   },
   "outputs": [],
   "source": [
    "gender_counts = incidents_dataset['participant_gender1'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Gender Distribution:\")\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with 'participant_gender1' equal to \"Male, female\"\n",
    "# Replace the column values where 'participant_gender1' is \"Male, female\" with \"Male\"\n",
    "incidents_dataset['participant_gender1'] = incidents_dataset['participant_gender1'].replace(\"Male, female\", \"Male\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "MfgOn-a1BjwD",
    "outputId": "ef95f56e-82a2-4407-f511-bcb8e8930cbc"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=incidents_dataset, x='participant_gender1', palette='flare', hue='participant_gender1', legend=False)\n",
    "plt.title('Distribution of Participant Genders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG8B0rj4EKy0"
   },
   "source": [
    "#### Number of Participants and Casualties\n",
    "\n",
    "In the next graph we show the distribution of the number of participants, and the number of injured, killed, arrested and unharmed participants. Even tough there are some outliers, the distribution is skewed to the right, since in most cases the number of participants is low and, on the contrary, there are very few cases with a large number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "TTTH_l3Z7iAG",
    "outputId": "22c9664f-01e9-4bf6-b9ef-8e28774e45ad"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=incidents_dataset[['n_participants', 'n_killed', 'n_injured','n_arrested', 'n_unharmed']])\n",
    "plt.title('Number of Participants and Casualties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YDR2SvcEF5U"
   },
   "source": [
    "#### Incident Characteristics\n",
    "\n",
    "In the next graph the top 10 most occurred incidents will be displayed, to see which where the main ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "vtndoHUx7teE",
    "outputId": "b7406278-1fd1-424e-a23b-aa53c58fc5a9"
   },
   "outputs": [],
   "source": [
    "# Get the total number of different incident characteristics and print them\n",
    "total_characteristics = incidents_dataset['incident_characteristics1'].nunique()\n",
    "print('- Number of different incident characteristics: ' + str(total_characteristics))\n",
    "\n",
    "# Get the top 10 most common incident characteristics\n",
    "top10_characteristics = incidents_dataset['incident_characteristics1'].value_counts().nlargest(10).index\n",
    "\n",
    "# Create a countplot with the top 10 incident characteristics\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=incidents_dataset, y='incident_characteristics1', order=top10_characteristics, palette='muted', hue='incident_characteristics1', legend=False)\n",
    "plt.title('Top 10 Most Common Incident Characteristics')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlation\n",
    "\n",
    "To perform pairwise correlation analysis, `corr()` function of `pandas` can be used, to compute the correlation matrix and then visualize it using a heatmap.\n",
    "\n",
    "The goal of pairwise correlation analysis is to understand the linear relationship between pairs of variables. The correlation coefficient ranges from -1 to 1, where:\n",
    "\n",
    "- 1 indicates a perfect positive correlation,\n",
    "- -1 indicates a perfect negative correlation, and\n",
    "- 0 indicates no correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns for correlation analysis\n",
    "numerical_columns = incidents_dataset.select_dtypes(include=['number'])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numerical_columns.corr()\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Pairwise Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incidents and Poverty Rates Correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'state' is the common column between incidents_dataset and pbsy_dataset\n",
    "merged_incidents_dataset_2 = pd.merge(incidents_dataset, pbsy_dataset, on='state', how='inner')\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix_incidents_poverty = merged_incidents_dataset_2[['n_killed', 'n_injured', 'povertyPercentage']].corr()\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix_incidents_poverty, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Incidents and Poverty Rates Correlation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incidents and Election Results Correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'state' is the common column between incidents_dataset and ysdh_dataset\n",
    "ysdh_dataset = ysdh_dataset.dropna()\n",
    "incidents_dataset = incidents_dataset.dropna()\n",
    "merged_incidents_dataset_3 = pd.merge(incidents_dataset, ysdh_dataset, on='state', how='inner')\n",
    "merged_incidents_dataset_3 = merged_incidents_dataset_3.dropna()\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix_incidents_election = merged_incidents_dataset_3[['n_killed', 'n_injured', 'party']].corr()\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix_incidents_election, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Incidents and Election Results Correlation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPHfyRbNzKcv"
   },
   "source": [
    "# Predictive Analysis\n",
    "\n",
    "**Authors:** \n",
    "- Marc Villalonga Llobera\n",
    "- Patxi Juaristi Pagegi\n",
    "\n",
    "**Date:** 08/01/2024\n",
    "\n",
    "---\n",
    "\n",
    "This Jupyter Notebook covers the third task of the project for the Data Mining subject of the Laurea Magistrale of the University of Pisa, focused in predictive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwQ_z05hzsLh"
   },
   "source": [
    "## Environment preparation and data reading\n",
    "\n",
    "First of all, we will install all the required packages, and then import the libraries that we will use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfOUKxJsznAp",
    "outputId": "efba5e14-dcaf-4881-fa82-c4351994e134"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!python -m pip install --upgrade pip\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "\n",
    "# AÃ±adir aqui si necesitamos otras librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the required libraries, we will read the datasets that we have exported in the task 1, which they contain the data filtered after the data preparation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the three datasets\n",
    "incidents_dataset = pd.read_csv('../project_datasets/incidents_v2.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature Definition\n",
    "\n",
    "First, we will define new feature that will enable classification for later predictions.\n",
    "\n",
    "### Time related features\n",
    "\n",
    "We will extract new features related with the moment that the incident occurred, based on the `date` column.\n",
    "\n",
    "- Extract month, day of the week, and year.\n",
    "- Create a feature for weekends or weekdays.\n",
    "- Create a feature for the season (spring, summer, autumn, winter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_dataset['date'] = pd.to_datetime(incidents_dataset['date'])  # Convert 'date' column to datetime format\n",
    "\n",
    "# Extract month, day of the week, and year\n",
    "incidents_dataset['month'] = incidents_dataset['date'].dt.month\n",
    "incidents_dataset['day_of_week'] = incidents_dataset['date'].dt.dayofweek\n",
    "incidents_dataset['year'] = incidents_dataset['date'].dt.year\n",
    "\n",
    "# Create a feature for weekends or weekdays\n",
    "incidents_dataset['is_weekend'] = (incidents_dataset['date'].dt.weekday >= 5).astype(int)\n",
    "\n",
    "# Create a feature for the season\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'spring'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'summer'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'autumn'\n",
    "    else:\n",
    "        return 'winter'\n",
    "\n",
    "incidents_dataset['season'] = incidents_dataset['month'].apply(get_season)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(incidents_dataset[['date', 'month', 'day_of_week', 'year', 'is_weekend', 'season']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical and participant features\n",
    "\n",
    "Then, we will create various new features that will take into account the state and city of the incident with the participant features.\n",
    "\n",
    "First of all, we will count the number of incidents per state and per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City and State Incident Count\n",
    "incidents_dataset['city_incident_count'] = incidents_dataset.groupby('city_or_county')['city_or_county'].transform('count')\n",
    "incidents_dataset['state_incident_count'] = incidents_dataset.groupby('state')['state'].transform('count')\n",
    "\n",
    "print(incidents_dataset[['city_or_county','state', 'city_incident_count', 'state_incident_count']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will create two columns, one for the state and the other for the city, where we will define an index, to analyze the severity of the incidents per area. This severity is obtained by the sum of the killed and injured people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City and State Severity Index\n",
    "incidents_dataset['city_severity_index'] = (incidents_dataset['n_killed'] + incidents_dataset['n_injured']) / incidents_dataset['city_incident_count']\n",
    "incidents_dataset['state_severity_index'] = (incidents_dataset['n_killed'] + incidents_dataset['n_injured']) / incidents_dataset['state_incident_count']\n",
    "\n",
    "print(incidents_dataset[['city_or_county','state', 'city_severity_index', 'state_severity_index']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add two columns for analyzing the average age of the incidents per zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City and State Average Age of Participants\n",
    "incidents_dataset['city_avg_age'] = incidents_dataset.groupby('city_or_county')['avg_age_participants'].transform('mean')\n",
    "incidents_dataset['state_avg_age'] = incidents_dataset.groupby('state')['avg_age_participants'].transform('mean')\n",
    "\n",
    "print(incidents_dataset[['city_or_county', 'state', 'city_avg_age', 'state_avg_age']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, since the female participation is quite lower than the male one, we will also add columns to get the female participation in each zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City and State Female Participation Rate\n",
    "incidents_dataset['city_female_participation_rate'] = (incidents_dataset['n_females'] / incidents_dataset['n_participants']) * 100\n",
    "incidents_dataset['state_female_participation_rate'] = (incidents_dataset['n_females'] / incidents_dataset.groupby('state')['n_participants'].transform('sum')) * 100\n",
    "\n",
    "print(incidents_dataset[['city_or_county', 'state', 'city_female_participation_rate', 'state_female_participation_rate']][4:12])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
